{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987c4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "def patchify(images, n_patches):\n",
    "  n,c,h,w, = images.shape\n",
    "  assert h==w , \"patchify method is implemented for square images only\"\n",
    "  patches=torch.zeros(n, n_patches**2,h*w//n_patches**2)\n",
    "  patch_size = h//n_patches\n",
    "\n",
    "  for idx, image in enumerate(images):\n",
    "    for i in range(n_patches):\n",
    "      for j in range(n_patches):\n",
    "        patch = image[: , i * patch_size : (i+1) * patch_size , j * patch_size : (j+1) * patch_size ]\n",
    "        patches[idx , i * n_patches + j ] = patch.flatten()\n",
    "  patches=patches.to(device)\n",
    "  return patches\n",
    "\n",
    "#Positional embeddings\n",
    "#A simple function that creates the positional embedding that will be added to the tokens. The main program shows the heatmap of such positional embeddings.\n",
    "\n",
    "def get_positional_embeddings(sequence_length,d):\n",
    "  result = torch.ones(sequence_length , d)\n",
    "  for i in range(sequence_length):\n",
    "    for j in range(d):\n",
    "      result[i][j] = np.sin(i/(10000 **(j/d))) if j % 2 == 0 else np.cos(i/(10000 **((j-1)/d)) )\n",
    "  return result\n",
    "\n",
    "class MyMSA(nn.Module):\n",
    "  def __init__(self,d , n_heads=2):\n",
    "    super(MyMSA,self).__init__()\n",
    "    self.d=d\n",
    "    self.n_heads=n_heads\n",
    "    assert d % n_heads == 0  , f\"cant divide dimension {d} into {n_heads} heads\"\n",
    "\n",
    "    d_head = int(d / n_heads)\n",
    "    self.q_mappings=nn.ModuleList([nn.Linear(d_head,d_head) for _ in range(self.n_heads)])\n",
    "    self.k_mappings = nn.ModuleList([nn.Linear(d_head,d_head) for _ in range(self.n_heads)])\n",
    "    self.v_mappings = nn.ModuleList([nn.Linear(d_head,d_head) for _ in range(self.n_heads)])\n",
    "\n",
    "    self.d_head = d_head\n",
    "    self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "\n",
    "  def forward(self, sequences):\n",
    "    #Sequences have shape (N, seq length, token length )\n",
    "    #We go into shape ()\n",
    "    #And come nack to\n",
    "    result=[]\n",
    "    for sequence in sequences:\n",
    "      seq_result=[]\n",
    "      for head in range(self.n_heads):\n",
    "        q_mapping = self.q_mappings[head]\n",
    "        k_mapping = self.k_mappings[head]\n",
    "        v_mapping  =self.v_mappings[head]\n",
    "\n",
    "        seq=sequence[: , head  * self.d_head : (head + 1)  * self.d_head]\n",
    "        q , k, v = q_mapping(seq) ,  k_mapping(seq) , v_mapping(seq)\n",
    "\n",
    "        attention = self.softmax(q @ k.T / (self.d_head ** 0.5))\n",
    "        seq_result.append(attention @ v)\n",
    "      result.append(torch.hstack(seq_result))\n",
    "    return torch.cat([torch.unsqueeze(r, dim=0) for r in result ])\n",
    "\n",
    "class MyViT(nn.Module):\n",
    "\n",
    "    def __init__(self, chw, n_patches=7,hidden_d=8, n_heads=2 , n_blocks=2, out_d=10):\n",
    "        # Super constructor\n",
    "        super(MyViT, self).__init__()\n",
    "\n",
    "        # Attributes\n",
    "        self.chw = chw  # (C,H,W)\n",
    "        self.n_patches = n_patches\n",
    "        self.hidden_d = hidden_d\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_heads=n_heads\n",
    "\n",
    "\n",
    "\n",
    "        # Inputs and patches sizes\n",
    "        assert chw[1] % n_patches == 0, 'Input shape not entirely divisible by number of patches '\n",
    "        assert chw[2] % n_patches == 0, \"Input shape not entirely divisible by number of projects \"\n",
    "        self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)\n",
    "\n",
    "        # 1) Linear mapper\n",
    "        self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)\n",
    "\n",
    "        # 2) Learnable classification token\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))\n",
    "\n",
    "        # 3) Positional Embedding\n",
    "        self.pos_embed = nn.Parameter(torch.tensor(get_positional_embeddings(self.n_patches ** 2 + 1, self.hidden_d)))\n",
    "        self.pos_embed.requires_grad = False\n",
    "\n",
    "        #4) Transformer encoder blocks\n",
    "        self.blocks = nn.ModuleList([MyViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])\n",
    "\n",
    "        #5) Classification MLPk\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.hidden_d,out_d) ,\n",
    "                                 nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self,images):\n",
    "\n",
    "        #Dividing images into patches\n",
    "        n, c, h, w = images.shape\n",
    "        patches =patchify(images , self.n_patches)\n",
    "\n",
    "        #Running Linear layer tokenization\n",
    "        #Map the vector corresponding to each patch to the hidden size dimension\n",
    "        tokens = self.linear_mapper(patches)\n",
    "\n",
    "        #Adding classification token to the tokens\n",
    "        tokens = torch.stack([torch.vstack((self.class_token, tokens[i])) for i in range(len(tokens))])\n",
    "\n",
    "        #Adding positional embedding\n",
    "        pos_embed = self.pos_embed.repeat(n,1,1)\n",
    "\n",
    "        out=tokens + pos_embed\n",
    "\n",
    "        #Transformer blocks\n",
    "        for block in self.blocks:\n",
    "            out=block(out)\n",
    "\n",
    "        #Getting the classification token only\n",
    "        out = out[:,0]\n",
    "\n",
    "        return self.mlp(out)  #Map to output dimension, output category distribution\n",
    "\n",
    "class MyViTBlock(nn.Module):\n",
    "    def __init__(self , hidden_d , n_heads , mlp_ratio=4):\n",
    "        super(MyViTBlock , self).__init__()\n",
    "        self.hidden_d = hidden_d\n",
    "        self.n_heads = n_heads\n",
    "        self.norm1 = nn.LayerNorm(hidden_d)\n",
    "        self.mhsa  =MyMSA(hidden_d , n_heads)\n",
    "        self.norm2  = nn.LayerNorm(hidden_d)\n",
    "        self.mlp = nn.Sequential(nn.Linear(hidden_d, mlp_ratio * hidden_d) ,\n",
    "                                 nn.GELU() ,\n",
    "                                 nn.Linear(mlp_ratio*hidden_d , hidden_d))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.mhsa(self.norm1(x))\n",
    "        out = out + self.mlp(self.norm2(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "if __name__=='__main__' :\n",
    "    # a=torch.randn(7,1,28,28)\n",
    "    # model = MyViT(chw=(1,28,28) , n_patches=7)\n",
    "\n",
    "\n",
    "\n",
    "    # lOADING dATA\n",
    "\n",
    "    transform = ToTensor()\n",
    "    train_set = MNIST(root='E:\\dataset', train=True, download=False, transform=transform)\n",
    "    test_set = MNIST(root='E:\\dataset', train=False, download=False, transform=transform)\n",
    "    train_loader = DataLoader(train_set, shuffle=True, batch_size=128)\n",
    "    test_loader = DataLoader(test_set, shuffle=False, batch_size=128)\n",
    "\n",
    "    # defining model and training options\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(\"using device :  model = MyViT((1,28,28), n_patches=7 , n_blocks=2 , hidden_d=8, n_heads=2, out_d=10).to(device)\", device, f\"\")\n",
    "    model = MyViT((1, 28, 28), n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10).to(device)\n",
    "\n",
    "    n_epochs = 5\n",
    "    lr = 0.005\n",
    "\n",
    "    # Training Loop\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs), desc='Training'):\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            x, y = batch\n",
    "            y =  y.to(device)\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "            print(loss.item())\n",
    "            train_loss = loss.detach().cpu().item() / len(train_loader)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    path = r'C:\\Users\\FastPc21\\Desktop\\mediaeval_2022\\2022-DisasterMM-main\\modelling'\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': criterion,\n",
    "    }, path)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
